{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Generic Packages\nimport numpy as np\nimport os\nimport pandas as pd\n\n#Machine Learning Library\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import shuffle           \n\n#Plotting Libraries\nimport seaborn as sn; sn.set(font_scale=1.4)\nimport matplotlib.pyplot as plt             \n\n#openCV\nimport cv2                                 \n\n#Tensor Flow\nimport tensorflow as tf    \n\n#Display Progress\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining Classes & Loading Data\n\nIn order to classify the images we need to pre-define the classes. Following are the pre-defined classes.\n\nMoutain, Street, Glacier, Buildings, Sea, Forest.\n\nEach image in our dataset will belong to one of the above classes & not both.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (150, 150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to Load Images & Labels\ndef load_data():\n    \n    datasets = ['../input/intel-image-classification/seg_train/seg_train', '../input/intel-image-classification/seg_test/seg_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Loading Data (Training & Test Dataset)\n(train_images, train_labels), (test_images, test_labels) = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images, train_labels = shuffle(train_images, train_labels, random_state=25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Visualisation & Pre-Processing\n\n"},{"metadata":{},"cell_type":"markdown","source":"Before moving on to Data Visualisation & Pre-Processing, we will do some exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Dataset Shape\nn_train = train_labels.shape[0]\nn_test = test_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of testing examples: {}\".format(n_test))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, train_counts = np.unique(train_labels, return_counts=True)\n_, test_counts = np.unique(test_labels, return_counts=True)\npd.DataFrame({'train': train_counts,'test': test_counts}, index=class_names).plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(train_counts,\n        explode=(0, 0, 0, 0, 0, 0) , \n        labels=class_names,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale the data\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualise the data [random image from training dataset]\n\ndef display_random_img(class_names, images, labels):\n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()\n    \n\ndisplay_random_img (class_names, train_images, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_examples(class_names, images, labels):\n   \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(10):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()\n\ndisplay_examples(class_names, train_images, train_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simple CNN Model\n\nModel Configuration:\n\n* Conv2D: (32 filters of size 3 by 3) The features will be \"extracted\" from the image.\n* MaxPooling2D: The images get half sized.\n* Flatten: Transforms the format of the images from a 2d-array to a 1d-array of 150 150 3 pixel values.\n* Relu : given a value x, returns max(x, 0).\n* Softmax: 6 neurons, probability that the image belongs to one of the classes."},{"metadata":{},"cell_type":"markdown","source":"#### **Build Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Compiling Model\n\n* Optimizer: adam = RMSProp + Momentum\n  * Momentum = takes into account past gradient to have a better update.\n  * RMSProp = exponentially weighted average of the squares of past gradients.\n  \n  \n* Loss function: we use sparse categorical crossentropy for classification, each images belongs to one class only\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **Model Training**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"history = model.fit(train_images, train_labels, batch_size=128, epochs=20, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_accuracy_loss(history):\n    \"\"\"\n        Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n    plt.title(\"train_acc vs val_acc\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()\n    \nplot_accuracy_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"test_loss = model.evaluate(test_images, test_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the accuracy we achieved was ~ 74% on the test images. This is not the best accuracy, however for this beginner's example it is good.\n\nLet us see this model's prediction accuracy on unseen data"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_images)     # Vector of probabilities\npred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n\ndisplay_random_img(class_names, test_images, pred_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can observe our model has a pretty accurate prediction of the image. However, as seen above the model accuracy is around 74%. This means that around 26% of the un-seen images will get an incorrect prediction.\n\nAt this stage either we can accept this accuracy (and keep quiet!) or do an error analysis and understand what sort of images are giving our model the jeepers !! "},{"metadata":{},"cell_type":"markdown","source":"### Error Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n    BOO = (test_labels == pred_labels)\n    mislabeled_indices = np.where(BOO == 0)\n    mislabeled_images = test_images[mislabeled_indices]\n    mislabeled_labels = pred_labels[mislabeled_indices]\n\n    title = \"Some examples of mislabeled images by the classifier:\"\n    display_examples(class_names,  mislabeled_images, mislabeled_labels)\n\nprint_mislabeled_images(class_names, test_images, test_labels, pred_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"CM = confusion_matrix(test_labels, pred_labels)\nax = plt.axes()\nsn.heatmap(CM, annot=True, \n           annot_kws={\"size\": 10}, \n           xticklabels=class_names, \n           yticklabels=class_names, ax = ax)\nax.set_title('Confusion matrix')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}